---
title: "2_Statistical_Learning"
author: "Pia Chouaifaty"
date: "11/1/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Conceptual Exercises

1. For each of parts (a) through (d), indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify your answer.  

*(a) The sample size n is extremely large, and the number of predictors p is small.*   
The flexible approach would be better as it would fit the data closer and produce a better fit than an inflexible approach.  

*(b) The number of predictors p is extremely large, and the number of observations n is small.*  
A flexible approach may overfit the small number of observations, so a less flexible approach may be better

*(c) The relationship between the predictors and response is highly non-linear.*  
A more flexible approach would be better

*(d) The variance of the error terms, i.e. σ2 = Var(ε), is extremely high.*  
A flexible method would be greatly affected by the noise and so would be a worse fit than a less-flexible method that is more resistant to the variance.

2. Explain whether each scenario is a classification or regression problem, and indicate whether we are most interested in inference or prediction. Finally, provide n and p.  

*(a) We collect a set of data on the top 500 firms in the US. For each firm we record profit, number of employees, industry and the CEO salary. We are interested in understanding which factors affect CEO salary.*  
This is a regression problem since all the variables except industry (qualitative) are continous and quantitative. Since we want to understand which predictors affect the salary, we are interested in inference.  
n: 500 firms  
p: profit, number of employees, industry  
Y: CEO salary  

*(b) We are considering launching a new product and wish to know whether it will be a success or a failure. We collect data on 20 similar products that were previously launched. For each product we have recorded whether it was a success or failure, price charged for the product, marketing budget, competition price, and ten other variables.*  
It is a classification and predictionproblem since we want to predict one of two possible outcomes (failure vs success).  
n: 20 products  
p: price, marketing, competition + 10 variables  
Y: success or failure

*(c) We are interested in predicting the % change in the USD/Euro exchange rate in relation to the weekly changes in the world stock markets. Hence we collect weekly data for all of 2012. For each week we record the % change in the USD/Euro, the % change in the US market, the % change in the British market, and the % change in the German market.*  
Regression problem since we want a specific % value as output. Prediction since we don't care about how predictors affect the outcome, we just want an accurate outcome.  
n: weekly 2012 observations (52 observations)  
p: %change in US market, % change in British market, % change in German market  
Y: % change in USD/Euro  

*5. What are the advantages and disadvantages of a very flexible (versus a less flexible) approach for regression or classification? Under what circumstances might a more flexible approach be preferred to a less flexible approach? When might a less flexible approach be preferred?*  
The advantages for a very flexible approach for regression or classification are obtaining a better fit for non-linear models, decreasing bias.  
The disadvantages for a very flexible approach for regression or classification are that requires estimating a greater number of parameters, follow the noise too closely (overfit), increasing variance.  
A more flexible approach would be preferred to a less flexible approach when we are interested in prediction and not the interpretability of the results.  
A less flexible approach would be preferred to a more flexible approach when we are interested in inference and the interpretability of the results.  

*6. Describe the differences between a parametric and a non-parametric statistical learning approach. What are the advantages of a para- metric approach to regression or classification (as opposed to a non- parametric approach)? What are its disadvantages?*  
A parametric approach reduces the problem of estimating f down to one of estimating a set of parameters because it assumes a form for f.  
A non-parametric approach does not assume a functional form for f and so requires a very large number of observations to accurately estimate f.  
The advantages of a parametric approach to regression or classification are the simplifying of modeling f to a few parameters and not as many observations are required compared to a non-parametric approach.  
The disadvantages of a parametric approach to regression or classification are a potential to inaccurately estimate f if the form of f assumed is wrong or to overfit the observations if more flexible models are used.  

*7. The table below provides a training data set containing six observations, three predictors, and one qualitative response variable.*  

```{r}
t7 = matrix(c(0, 2, 0, 0, -1, 1, 3, 0, 1, 1, 0, 1, 0, 0, 3, 2, 1, 1, "Red", "Red", "Red", "Green", "Green", "Red"), nrow = 6, ncol = 4)
colnames(t7)=c("X1", "X2", "X3", "Y")
t7
```

*Suppose we wish to use this data set to make a prediction for Y when X1 = X2 = X3 = 0 using K-nearest neighbors.*  

*(d) If the Bayes decision boundary in this problem is highly non- linear, then would we expect the best value for K to be large or small? Why?*  
Small. A small K would be flexible for a non-linear decision boundary, whereas a large K would try to fit a more linear boundary because it takes more points into consideration.

## Applied Exercises

*8. This exercise relates to the College data set, which can be found in the file College.csv. It contains a number of variables for 777 different universities and colleges in the US. The variables are:*  

- Private : Public/private indicator
- Apps : Number of applications received
- Accept : Number of applicants accepted
- Enroll : Number of new students enrolled
- Top10perc : New students from top 10 % of high school class 
- Top25perc : New students from top 25 % of high school class 
- F.Undergrad : Number of full-time undergraduates
- P.Undergrad : Number of part-time undergraduates
- Outstate : Out-of-state tuition
- Room.Board : Room and board costs
- Books : Estimated book costs
- Personal : Estimated personal spending
- PhD : Percent of faculty with Ph.D.’s
- Terminal : Percent of faculty with terminal degree
- S.F.Ratio : Student/faculty ratio
- perc.alumni : Percent of alumni who donate
- Expend : Instructional expenditure per student
- Grad.Rate : Graduation rate

*Before reading the data into R, it can be viewed in Excel or a text editor.*
*(a) Use the read.csv() function to read the data into R. Call the loaded data college. Make sure that you have the directory set to the correct location for the data.*  

```{r}
college = read.csv("/Users/piachouaifaty/ISLR_Data/College.csv")
college
```

*(b) Look at the data using the fix() function. You should notice that the first column is just the name of each university. We don’t really want R to treat this as data. However, it may be handy to have these names for later.* 

```{r}
rownames(college)=college[,1]
college=college[,-1]
college
```

*Use the summary() function to produce a numerical summary of the variables in the data set.*

```{r}
summary(college)
```

*Use the pairs() function to produce a scatterplot matrix of the first ten columns or variables of the data. Recall that you can reference the first ten columns of a matrix A using A[,1:10].*

```{r}
college$Private=as.factor(college$Private)
pairs(college[,1:10])
```

*Use the plot() function to produce side-by-side boxplots of Outstate versus Private.*

```{r}
plot(college$Private, college$Outstate)
```

*Create a new qualitative variable, called Elite, by binning the Top10perc variable. We are going to divide universities into two groups based on whether or not the proportion of students coming from the top 10% of their high school classes exceeds 50 %.*

```{r}
Elite=rep("No", nrow(college))
Elite[college$Top10perc>50]="Yes"
Elite=as.factor(Elite)
college=cbind(college, Elite)
college
```

*Use the summary() function to see how many elite universities there are. Now use the plot() function to produce side-by-side boxplots of Outstate versus Elite.*

```{r}
summary(college$Elite)
```

```{r}
plot(college$Elite, college$Outstate)
```

*Use the hist() function to produce some histograms with differing numbers of bins for a few of the quantitative variables. You may find the command par(mfrow=c(2,2)) useful: it will divide the print window into four regions so that four plots can be made simultaneously. Modifying the arguments to this function will divide the screen in other ways.*

```{r}
par(mfrow=c(2,2))
hist(college$Enroll, breaks = 10)
hist(college$Accept, breaks = 20)
hist(college$PhD, breaks = 5)
hist(college$Apps)
```

*Continue exploring the data, and provide a brief summary of what you discover.*  

```{r}
par(mfrow=c(1,1))
plot(college$Accept / college$Apps, college$S.F.Ratio)
```

Selective universities tend to have a lower S:F ratio

```{r}
plot(college$Top10perc, college$Grad.Rate)
```

There is an outlier, there cannot be a graduation rate higher than 100%  

*9. This exercise involves the Auto data set studied in the lab. Make sure that the missing values have been removed from the data.*


```{r}
Auto=read.table("/Users/piachouaifaty/ISLR_Data/Auto.data", header=T, na.strings = "?")
#tells R to treat question marks as NA
length(which(is.na(Auto)))
```
```{r}
Auto=na.omit(Auto)
length(which(is.na(Auto)))
```

```{r}
dim(Auto)
summary(Auto)
```

*(a) Which of the predictors are quantitative, and which are qualitative?*  
quantitative: mpg, cylinders, displacement, horsepower, weight, acceleration, year  
qualitative: name, origin  

*(b) What is the range of each quantitative predictor? You can answer this using the range() function.*  
```{r}
v=c("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "year")
sapply(Auto[,v], range)
```

*(c) What is the mean and standard deviation of each quantitative predictor?*

```{r}
sapply(Auto[,v], mean)
```
```{r}
sapply(Auto[,v], sd)
```

*(d) Now remove the 10th through 85th observations. What is the range, mean, and standard deviation of each predictor in the subset of the data that remains?*

```{r}
Auto2 = Auto[-(10:85),]
sapply(Auto2[,v], range)
sapply(Auto2[,v], mean)
sapply(Auto2[,v], sd)
```

*(e) Using the full data set, investigate the predictors graphically, using scatterplots or other tools of your choice. Create some plots highlighting the relationships among the predictors. Comment on your findings.*

```{r}
pairs(Auto[,v]) #quantitative only
```

```{r}
plot(Auto$mpg, Auto$weight)
```
Heavier weight correlates with lower mpg  

```{r}
plot(Auto$mpg, Auto$cylinders)
```
More cylinders, less mpg.  

```{r}
plot(Auto$mpg, Auto$year)
```
Cars become more efficient over time. (Given that the data is time-ordered)


*10. This exercise involves the Boston housing data set.*
*(a) To begin, load in the Boston data set. The Boston data set is part of the MASS library in R.*

```{r}
library(MASS)
Boston
?Boston
```

*How many rows are in this data set? How many columns? What do the rows and columns represent?*

```{r}
attach(Boston)
dim(Boston)
```
506 rows, 14 columns. Rows are the suburbs and columns are attributes/features.  

*(b) Make some pairwise scatterplots of the predictors (columns) in this data set. Describe your findings.*  

```{r}
pairs(Boston)
```

*(c) Are any of the predictors associated with per capita crime rate? If so, explain the relationship.*

```{r}
par(mfrow=c(2,3))
plot(Boston$age, Boston$crim)
# Older homes, more crime
plot(Boston$dis, Boston$crim)
# Closer to work-area, more crime
plot(Boston$rad, Boston$crim)
# Higher index of accessibility to radial highways, more crime
plot(Boston$tax, Boston$crim)
# Higher tax rate, more crime
plot(Boston$ptratio, Boston$crim)
# Higher pupil:teacher ratio, more crime
```

*(d) Do any of the suburbs of Boston appear to have particularly high crime rates? Tax rates? Pupil-teacher ratios? Comment on the range of each predictor.*

```{r}
par(mfrow=c(1,1))
hist(Boston$crim, breaks=25)
```
```{r}
hist(Boston$crim[Boston$crim>30])
```
```{r}
length((Boston$crim[Boston$crim>20]))
```
There are 18 suburbs with a per capita crime rate greater than 20

```{r}
hist(Boston$tax, breaks=25)
```
there is a large divide between suburbs with low tax rates and a peak at 660-680   

```{r}
hist(Boston$ptratio, breaks=25)
```
a skew towards high ratios, but no particularly high ratios  

*How many of the suburbs in this data set bound the Charles river?*

```{r}
dim(subset(Boston, chas == 1))
```
35 suburbs  

*What is the median pupil-teacher ratio among the towns in this data set?*

```{r}
median(Boston$ptratio)
```

*Which suburb of Boston has lowest median value of owner-occupied homes? What are the values of the other predictors for that suburb, and how do those values compare to the overall ranges for those predictors? Comment on your findings.*

```{r}
t(subset(Boston, medv == min(Boston$medv)))
```
Two suburbs with the lowest medv.  

```{r}
t(sapply(Boston, range))
```

*(h) In this data set, how many of the suburbs average more than seven rooms per dwelling? More than eight rooms per dwelling? Comment on the suburbs that average more than eight rooms per dwelling.*

```{r}
seven_r=subset(Boston, rm>7)
eight_r=subset(Boston, rm>8)

dim(seven_r)
dim(eight_r)
```

```{r}
"eight rooms:"
summary(eight_r)
"Entire dataset:"
summary(Boston)
```
relatively lower crime (comparing range), lower lstat (comparing range) 




